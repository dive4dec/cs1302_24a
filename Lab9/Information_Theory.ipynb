{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9877320a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "title: Information Theory\n",
    "math:\n",
    "    '\\abs': '\\left\\lvert #1 \\right\\rvert'\n",
    "    '\\orm': '\\left\\lvert #1 \\right\\rvert'\n",
    "    '\\Set': '\\left\\{ #1 \\right\\}'\n",
    "    '\\set': '\\operatorname{set}'   \n",
    "    '\\mc': '\\mathcal{#1}'\n",
    "    '\\M': '\\boldsymbol{#1}'\n",
    "    '\\R': '\\mathsf{#1}'\n",
    "    '\\RM': '\\boldsymbol{\\mathsf{#1}}'\n",
    "    '\\op': '\\operatorname{#1}'\n",
    "    '\\E': '\\op{E}'\n",
    "    '\\d': '\\mathrm{\\mathstrut d}'\n",
    "    '\\SFM': '\\operatorname{SFM}'\n",
    "    '\\utag': '\\stackrel{\\text{(#1)}}{#2}'\n",
    "    '\\uref': '\\text{(#1)}'\n",
    "    '\\minimal': '\\operatorname{minimal}'\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd7931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __init__ import install_dependencies\n",
    "\n",
    "await install_dependencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a5dd5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As mentioned in previous lectures, the following two lists `coin_flips` and `dice_rolls` simulate the random coin flips and rollings of a dice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a2ee23",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Do NOT modify any variables defined here because some tests rely on them\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "%matplotlib widget\n",
    "%reload_ext divewidgets\n",
    "\n",
    "random.seed(0)  # for reproducible results.\n",
    "num_trials = 200\n",
    "coin_flips = [\"H\" if random.random() <= 1 / 2 else \"T\" for i in range(num_trials)]\n",
    "dice_rolls = [random.randint(1, 6) for i in range(num_trials)]\n",
    "print(\"coin flips: \", *coin_flips)\n",
    "print(\"dice rolls: \", *dice_rolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3bc8da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**What is the difference of the two random processes? Can we say one process has more information content than the other?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495616b9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In this lab, we will use dictionaries to store distributions and then compute their information content using information theory, which was introduced by [*Claude E. Shannon*](https://en.wikipedia.org/wiki/Claude_Shannon) in his [seminal work in 1948](https://doi.org/10.1002%2Fj.1538-7305.1948.tb01338.x). It has [numerous applications](https://www.khanacademy.org/computing/computer-science/informationtheory): \n",
    "\n",
    "- *Compression* (to keep files small).\n",
    "- *Communications* (to send data to mobile phones).\n",
    "- *Cybersecurity* (to protect data using provably secure methods).\n",
    "- *Machine learning* (to identify relevant features for learning).\n",
    "\n",
    "The first [conference on Information Theory](https://en.wikipedia.org/wiki/IEEE_International_Symposium_on_Information_Theory) was held in London in 1950, where [Alan Turing also contributed](https://www.turing.org.uk/sources/info50turing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db8f35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d54d67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The following code shown in the lecture uses a dictionary to store the [(empirical) distribution](https://en.wikipedia.org/wiki/Empirical_distribution_function#:~:text=The%20empirical%20distribution%20function%20is,to%20the%20Glivenko%E2%80%93Cantelli%20theorem.) for a sequence efficiently without storing outcomes with zero counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b2f48",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4b2de65a3f67be34d7891c2fb16828a",
     "grade": false,
     "grade_id": "dist",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Do NOT modify any variables defined here because some tests rely on them\n",
    "def distribute(seq):\n",
    "    \"\"\"Returns a dictionary where each value in a key-value pair is\n",
    "    the probability of the associated key occurring in the sequence.\n",
    "    \"\"\"\n",
    "    p = {}\n",
    "    for i in seq:\n",
    "        p[i] = p.get(i, 0) + 1 / len(seq)\n",
    "    return p\n",
    "\n",
    "\n",
    "# tests\n",
    "coin_flips_dist = distribute(coin_flips)\n",
    "dice_rolls_dist = distribute(dice_rolls)\n",
    "print(\"Distribution of coin flips:\", coin_flips_dist)\n",
    "print(\"Distribution of dice rolls:\", dice_rolls_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2209599",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "::::{prf:definition} probability mass function (pmf)\n",
    "\n",
    "A distribution on discrete outcomes is a collection of non-negative probability masses\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\M{p} &=\\begin{bmatrix} p_{i} \\end{bmatrix}_{i\\in \\mc{S}} && \\text{such that}\\\\\n",
    "\\sum_{i\\in \\mc{S}} p_i &= 1, && \\text{where}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- $\\mc{S}$ is the set of distinct outcomes.\n",
    "- $p_i$ denotes the probability (chance) of seeing outcome $i$.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0204359",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can verify that the probabilities $p_i$'s have to sum to $1$ for the empirical distributions of coin flips and dice rolls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a66b6c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "assert math.isclose(sum(coin_flips_dist.values()), 1) and math.isclose(\n",
    "    sum(dice_rolls_dist.values()), 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad0e3b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**How to measure the information content?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b76c1ff",
   "metadata": {},
   "source": [
    "::::{card}\n",
    ":header: Entropy\n",
    ":footer: [(open in new tab)](https://www.youtube.com/embed/2s3aJfRr9gE)\n",
    "\n",
    ":::{iframe} https://www.youtube.com/embed/2s3aJfRr9gE\n",
    ":align: center\n",
    ":width: 100%\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb8b16",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{prf:definition} Entropy\n",
    ":label: def:entropy\n",
    "\n",
    "In information theory, the information content of a distribution is measured by its [*entropy*](https://en.wikipedia.org/wiki/Entropy_(information_theory)) defined as:\n",
    "\n",
    "$$ \n",
    "\\begin{aligned} \n",
    "H(\\M{p}) &:= \\sum_{i\\in \\mc{S}} p_i \\overbrace{\\log_2 \\tfrac{1}{p_i}}^{\\text{called surprise} } \\\\ \n",
    "&= - \\sum_{i\\in \\mc{S}} p_i \\log_2 p_i \\kern1em \\text{(bits)} \\end{aligned}  \n",
    "$$\n",
    "\n",
    "with $p_i \\log_2 \\frac{1}{p_i} = 0$ if $p_i = 0$ because $\\lim_{x\\downarrow 0} x \\log_2 \\frac1x = 0$.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85161aef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For instance, if $\\M{p}=(p_{H},p_{T})=(0.5,0.5)$, then\n",
    "\n",
    "$$\n",
    "\\begin{aligned} H(\\M{p}) &= 0.5 \\log_2 \\frac{1}{0.5} + 0.5 \\log_2 \\frac{1}{0.5} \\\\ &= 0.5 + 0.5 = 1  \\text{ bit,}\\end{aligned} \n",
    "$$\n",
    "\n",
    "i.e., an outcome of a fair coin flip has one bit of information content, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f1e914",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On the other hand, if $\\M{p}=(p_{H},p_{T})=(1,0)$, then\n",
    "\n",
    "$$\n",
    "\\begin{aligned} H(\\M{p}) &= 1 \\log_2 \\frac{1}{1} + 0 \\log_2 \\frac{1}{0} \\\\ &= 0 + 0 = 0  \\text{ bits,}\\end{aligned} \n",
    "$$\n",
    "\n",
    "i.e., an outcome of a biased coin flip that always comes up head has no information content, again as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a03e02",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{exercise}\n",
    ":label: ex:entropy\n",
    "\n",
    "Define a function `entropy` that\n",
    "- takes a distribution $\\M{p}$ as its argument, and\n",
    "- returns the entropy $H(\\M{p})$.\n",
    "\n",
    "Handle the case when $p_i=0$, e.g., using the short-circuit evaluation of logical `and`.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156107cf",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d8b093d82544bb44166bedee3ec3398",
     "grade": false,
     "grade_id": "entropy",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def entropy(dist):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3698549",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1eed6deedf3bc6f5c779b373b29abd9",
     "grade": true,
     "grade_id": "test-entropy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "assert math.isclose(entropy({\"H\": 0.5, \"T\": 0.5}), 1)\n",
    "assert math.isclose(entropy({\"H\": 1, \"T\": 0}), 0)\n",
    "assert math.isclose(entropy(dict.fromkeys(range(1, 7), 1 / 6)), math.log2(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66580323",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfbe83abf3b144cd671cf4cea18cf08a",
     "grade": true,
     "grade_id": "h_test-entropy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e589080",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uniform distribution maximizes entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172c9c0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Intuitively,\n",
    "- for large enough numbers of fair coin flips, we should have $\\mc{S}=\\{H,T\\}$ and $p_H=p_T=0.5$, i.e., equal chance for head and tail.\n",
    "- for large enough numbers of fair dice rolls, we should have $p_i=\\frac16$ for all $i\\in \\mc{S}=\\{1,2,3,4,5,6\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(seq, *args, **kwargs):\n",
    "    fig = plt.figure(*args, **kwargs)\n",
    "    plt.xlabel(\"Outcomes\")\n",
    "    plt.title(\"Distribution\")\n",
    "    plt.ylim(0, 1)\n",
    "    dist_plot = ()\n",
    "\n",
    "    @widgets.interact(\n",
    "        n=widgets.IntSlider(\n",
    "            value=1,\n",
    "            min=1,\n",
    "            max=len(seq),\n",
    "            step=1,\n",
    "            description=\"n:\",\n",
    "            continuous_update=False,\n",
    "        )\n",
    "    )\n",
    "    def plot(n):\n",
    "        plt.figure(fig.number)\n",
    "        nonlocal dist_plot\n",
    "        dist_plot and dist_plot.remove()\n",
    "        dist = distribute(seq[:n])\n",
    "        dist_plot = plt.stem(dist.keys(), dist.values())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d838e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(coin_flips, num=1, clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279e924",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plot_distribution(dice_rolls, num=2, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c98f13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "source": [
    "::::{prf:definition} Uniform\n",
    ":label: def:uniform-distribution\n",
    "\n",
    "A distribution is called a *uniform distribution* if all its distinct outcomes have the same probability of occurring, i.e.,\n",
    "\n",
    "$$ p_i = \\frac{1}{|\\mc{S}|}\\kern1em  \\text{for all }i\\in \\mc{S},  $$\n",
    "\n",
    "where $|\\mc{S}|$ is the mathematical notation to denote the size of the set $\\mc{S}$.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6450622e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{exercise}\n",
    ":label: ex:uniform\n",
    "\n",
    "Define a function `uniform` that\n",
    "- takes a sequence of possibly duplicate outcomes, and\n",
    "- returns a uniform distribution of the distinct outcomes.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cfe385",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0e63546093486224bba1a6115cc39c4",
     "grade": false,
     "grade_id": "uniform",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def uniform(outcomes):\n",
    "    \"\"\"Returns the uniform distribution (dict) over distinct items in outcomes.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a9dbc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46816ed3122a6ad3d5d4dcf6e943e6d9",
     "grade": true,
     "grade_id": "test-uniform",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "assert uniform(\"HT\") == {\"H\": 0.5, \"T\": 0.5}\n",
    "assert uniform(\"HTH\") == {\"H\": 0.5, \"T\": 0.5}\n",
    "fair_dice_dist = uniform(range(1, 7))\n",
    "assert all(\n",
    "    math.isclose(fair_dice_dist[k], v)\n",
    "    for k, v in {\n",
    "        1: 0.16666666666666666,\n",
    "        2: 0.16666666666666666,\n",
    "        3: 0.16666666666666666,\n",
    "        4: 0.16666666666666666,\n",
    "        5: 0.16666666666666666,\n",
    "        6: 0.16666666666666666,\n",
    "    }.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd9c70",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "602204ce39a176e65792cc0c227fa0ce",
     "grade": true,
     "grade_id": "h_test-uniform",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcca8756",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**What is the entropy for uniform distributions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b03cf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By definition,\n",
    "\n",
    "$$ \\begin{aligned} H(\\M{p}) &:= \\sum_{i\\in \\mc{S}} p_i \\log_2 \\tfrac{1}{p_i} \\\\ &= \\sum_{i\\in \\mc{S}} \\frac{1}{|\\mc{S}|} \\log_2 |\\mc{S}| = \\log_2 |\\mc{S}|  \\kern1em \\text{(bits)} \\end{aligned}  $$\n",
    "\n",
    "Entropy reduces to the formula in [Lab 1](../Lab1/Binary_Code.ipynb) regarding the number of bits required to encode a set of integers or characters. It is the maximum possible entropy for a given finite set of possible outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1763b66",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Use this result to test whether you have implemented both `entropy` and `uniform` correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71199197",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "assert all(\n",
    "    math.isclose(entropy(uniform(range(n))), math.log2(n)) for n in range(1, 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea6b08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Joint distribution and its entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399c2f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we duplicate a sequence of outcomes, the total information content should remain unchanged, *not* doubled, because the duplicate contains the same information as the original. We will verify this fact by creating a [joint distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0d78b",
   "metadata": {},
   "source": [
    "::::{prf:definition} joint pmf\n",
    "\n",
    "The joint distribution on discrete outcomes is a collection of non-negative probability masses\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\M{p} &=\\begin{bmatrix} p_{ij} \\end{bmatrix}_{i\\in \\mc{S},j\\in \\mc{T}}, && \\text{such that}\\\\\n",
    "\\sum_{i\\in \\mc{S}} \\sum_{j\\in \\mc{T}} p_{ij} &= 1, && \\text{where}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- $\\mc{S}$ and $\\mc{T}$ are sets of outcomes.\n",
    "- $p_{ij}$ is the chance we see outcomes $i$ and $j$ simultaneously. The subscript $ij$ in $p_{ij}$ denotes a tuple $(i,j)$, NOT the multiplication $i\\times j$.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad5ca1c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{exercise}\n",
    ":label: ex:jointly-distribute\n",
    "\n",
    "Define a function `jointly_distribute` that \n",
    "- takes two sequences, `seq1` and `seq2`, of outcomes with the same length, and\n",
    "- returns the joint distribution represented as a dictionary where each key-value pair has the key being a tuple `(i,j)` associated with the probability $p_{ij}$ of seeing `(i,j)` in `zip(seq1,seq2)`.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458bc48",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75003109647008d1c6a34e5b3f67ad12",
     "grade": false,
     "grade_id": "jointly_distribute",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def jointly_distribute(seq1, seq2):\n",
    "    \"\"\"Returns the joint distribution of the tuple (i,j) of outcomes from zip(seq1,seq2).\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8db4a0",
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cafde4d116e9b3156e115adb000b2b1",
     "grade": true,
     "grade_id": "test-jointly_distribute",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "assert jointly_distribute(\"HT\", \"HT\") == {(\"H\", \"H\"): 0.5, (\"T\", \"T\"): 0.5}\n",
    "assert jointly_distribute(\"HHTT\", \"HTHT\") == {\n",
    "    (\"H\", \"H\"): 0.25,\n",
    "    (\"H\", \"T\"): 0.25,\n",
    "    (\"T\", \"H\"): 0.25,\n",
    "    (\"T\", \"T\"): 0.25}\n",
    "coin_flips_duplicate_dist = {\n",
    "    (\"T\", \"T\"): 0.5350000000000004,\n",
    "    (\"H\", \"H\"): 0.4650000000000003}\n",
    "coin_flips_duplicate_ans = jointly_distribute(coin_flips, coin_flips)\n",
    "assert all(\n",
    "    math.isclose(coin_flips_duplicate_ans[i], pi)\n",
    "    for i, pi in coin_flips_duplicate_dist.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2dfba7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6aca1ca70dd9aa6a7e077ab872ce9fc6",
     "grade": true,
     "grade_id": "h_test-jointly_distribute",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f364f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you have implemented `entropy` and `jointly_distribute` correctly, you can verify that duplicating a sequence will give the same entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e809564",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "assert math.isclose(\n",
    "    entropy(jointly_distribute(coin_flips, coin_flips)), entropy(distribute(coin_flips))\n",
    ")\n",
    "assert math.isclose(\n",
    "    entropy(jointly_distribute(dice_rolls, dice_rolls)), entropy(distribute(dice_rolls))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b535e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, for two sequences generated independently, the joint entropy is roughly the sum of the individual entropies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b6ef26",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "coin_flips_entropy = entropy(distribute(coin_flips))\n",
    "dice_rolls_entropy = entropy(distribute(dice_rolls))\n",
    "cf_dr_entropy = entropy(jointly_distribute(coin_flips, dice_rolls))\n",
    "print(\n",
    "    f\"\"\"Entropy of coin flip: {coin_flips_entropy}\n",
    "Entropy of dice roll: {dice_rolls_entropy}\n",
    "Sum of the above entropies: {coin_flips_entropy + dice_rolls_entropy}\n",
    "Joint entropy: {cf_dr_entropy}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8f2bd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Conditional distribution and entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01301837",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "::::{prf:definition} conditional pmf\n",
    "\n",
    "A [conditional distribution](https://en.wikipedia.org/wiki/Conditional_probability_distribution) on discrete outcomes is a collection of non-negative probability masses\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\M{q} &:=\\begin{bmatrix} q_{j|i} \\end{bmatrix}_{i\\in \\mc{S}, j\\in \\mc{T}} && \\text{such that}\\\\\n",
    "\\sum_{j\\in \\mc{T}} q_{j|i} &= 1 \\kern1em \\text{for all }i\\in \\mc{S}, && \\text{where}\n",
    "\\end{align}\n",
    "$$ \n",
    "\n",
    "where \n",
    "- $\\mc{S}$ and $\\mc{T}$ are two sets of distinct outcomes, and\n",
    "- $q_{j|i}$ denotes the probability (chance) of seeing outcome $j$ given the condition that outcome $i$ is observed.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d7894",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, suppose we want to compute the distribution of coin flips given dice rolls, then the following assign `q_H_1` and `q_T_1` to the values $q_{H|1}$ and $q_{T|1}$ respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1de9a7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "coin_flips_1 = [j for i, j in zip(dice_rolls, coin_flips) if i == 1]\n",
    "q_H_1 = coin_flips_1.count(\"H\") / len(coin_flips_1)\n",
    "q_T_1 = coin_flips_1.count(\"T\") / len(coin_flips_1)\n",
    "print(\"Coin flips given dice roll is 1:\", coin_flips_1)\n",
    "print(\n",
    "    'Distribution of coin flip given dice roll is 1: {{ \"H\": {}, \"T\": {}}}'.format(\n",
    "        q_H_1, q_T_1\n",
    "    )\n",
    ")\n",
    "assert math.isclose(q_H_1 + q_T_1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92971c8b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that `q_H_1 + q_T_1` is 1 as expected. Similarly, we can assign `q_H_2` and `q_T_2` to the values $q_{H|2}$ and $q_{T|2}$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234934a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "coin_flips_2 = [j for i, j in zip(dice_rolls, coin_flips) if i == 2]\n",
    "q_H_2 = coin_flips_2.count(\"H\") / len(coin_flips_2)\n",
    "q_T_2 = coin_flips_2.count(\"T\") / len(coin_flips_2)\n",
    "print(\"Coin flips given dice roll is 2:\", coin_flips_2)\n",
    "print(\n",
    "    'Distribution of coin flip given dice roll is 2: {{ \"H\": {}, \"T\": {}}}'.format(\n",
    "        q_H_2, q_T_2\n",
    "    )\n",
    ")\n",
    "assert math.isclose(q_H_2 + q_T_2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983663e9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Finally, we want to store the conditional distribution as a nested dictionary so that `q[i]` points to the distribution \n",
    "\n",
    "$$\\begin{bmatrix} q_{j|i} \\end{bmatrix}_{j\\in \\mc{T}} \\kern1em \\text{for }i\\in \\mc{S}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19e736",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "q = {}\n",
    "q[1] = dict(zip(\"HT\", (q_H_1, q_T_1)))\n",
    "q[2] = dict(zip(\"HT\", (q_H_2, q_T_2)))\n",
    "...  # entries for q[i] other possible outcomes i of the dice rolls.\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276bf6f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{exercise}\n",
    ":label: ex:conditionally-distribute\n",
    "\n",
    "Define a function `conditionally_distribute` that\n",
    "- takes two sequences `seq1` and `seq2` of outcomes of the same length, and\n",
    "- returns the conditional distribution of `seq2` given `seq1` in the form of a nested dictionary efficiently without storing the unobserved outcomes.\n",
    "\n",
    "In the above example, `seq1` is `dice_rolls` while `seq2` is `coin_flips`.\n",
    "\n",
    ":::{hint}\n",
    ":class: dropdown\n",
    "\n",
    "For an efficient implementation without traversing the input sequences too many times, consider using the following solution template and the `setdefault` method.\n",
    "```python\n",
    "def conditionally_distribute(seq1, seq2):\n",
    "    q, count = {}, {}  # NOT q = count = {}\n",
    "    for i in seq1:\n",
    "        count[i] = count.get(i, 0) + 1\n",
    "    for i, j in zip(seq1, seq2):\n",
    "        q[i][j] = ...\n",
    "    return q\n",
    "```\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb79d8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c019313def0b8c1f770b421dacfa4d38",
     "grade": false,
     "grade_id": "conditionally_distribute",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def conditionally_distribute(seq1, seq2):\n",
    "    \"\"\"Returns the conditional distribution q of seq2 given seq1 such that\n",
    "    q[i] is a dictionary for observed outcome i in seq1 and\n",
    "    q[i][j] is the probability of observing j in seq2 given the\n",
    "    corresponding outcome in seq1 is i.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd597ece",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c7d8058dffae0e55f56f60bc0b402e4",
     "grade": true,
     "grade_id": "test-conditionally_distribute",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "cf_given_dr_dist = {\n",
    "    4: {\"T\": 0.5588235294117647, \"H\": 0.4411764705882353},\n",
    "    1: {\"T\": 0.46511627906976744, \"H\": 0.5348837209302325},\n",
    "    3: {\"H\": 0.5135135135135135, \"T\": 0.4864864864864865},\n",
    "    6: {\"H\": 0.5454545454545454, \"T\": 0.45454545454545453},\n",
    "    2: {\"T\": 0.7586206896551724, \"H\": 0.2413793103448276},\n",
    "    5: {\"T\": 0.5416666666666666, \"H\": 0.4583333333333333}}\n",
    "cf_given_dr_ans = conditionally_distribute(dice_rolls, coin_flips)\n",
    "assert all(\n",
    "    math.isclose(cf_given_dr_ans[i][j], v)\n",
    "    for i, d in cf_given_dr_dist.items()\n",
    "    for j, v in d.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e5c4f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93d8a43a0f72b34a78bb579567a44ea4",
     "grade": true,
     "grade_id": "h_test-conditionally_distribute",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d6ff49",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "::::{prf:definition} Conditional entropy\n",
    ":label: def:conditional-entropy\n",
    "\n",
    "The [*conditional entropy*](https://en.wikipedia.org/wiki/Conditional_entropy) is defined for a conditional distribution $\\M{q}=\\begin{bmatrix} q_{j|i} \\end{bmatrix}_{i\\in \\mc{S},j\\in\\mc{T}}$ and a distribution $\\M{p}=\\begin{bmatrix} p_i \\end{bmatrix}_{i\\in \\mc{S}}$ as follows:\n",
    "\n",
    "$$ H(\\M{q}|\\M{p}) = \\sum_{i\\in \\mc{S}} p_i \\sum_{j\\in \\mc{T}} q_{j|i} \\log_2 \\frac{1}{q_{j|i}}, $$\n",
    "where, by convention:  \n",
    "1. The summand of the outer sum is 0 if $p_i=0$ (regardless of the values of $q_{j|i}$).\n",
    "2. The summand of the inner sum is 0 if $q_{j|i}=0$.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28b666",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "::::{exercise}\n",
    ":label: ex:conditional-entropy\n",
    "\n",
    "Define a function `conditional_entropy` that\n",
    "- takes \n",
    "  1. a distribution `p` as its first argument,\n",
    "  2. a conditional distribution `q` as its second argument, and\n",
    "- returns the conditional entropy $H(\\M{q}|\\M{p})$.\n",
    "\n",
    "Handle the cases when $p_i=0$ and $q_{j|i}=0$ for some indices $i$ and $j$.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abbf993",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca08552577ed718dff1db0a865044a85",
     "grade": false,
     "grade_id": "conditional_entropy",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ddb9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f0bd42d5a71341fbe7cbbfafd8dbb09",
     "grade": true,
     "grade_id": "test-conditional_entropy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "cf_given_dr_dist = {\n",
    "    4: {\"T\": 0.5588235294117647, \"H\": 0.4411764705882353},\n",
    "    1: {\"T\": 0.46511627906976744, \"H\": 0.5348837209302325},\n",
    "    3: {\"H\": 0.5135135135135135, \"T\": 0.4864864864864865},\n",
    "    6: {\"H\": 0.5454545454545454, \"T\": 0.45454545454545453},\n",
    "    2: {\"T\": 0.7586206896551724, \"H\": 0.2413793103448276},\n",
    "    5: {\"T\": 0.5416666666666666, \"H\": 0.4583333333333333}}\n",
    "assert (\n",
    "    conditional_entropy(\n",
    "        {\"H\": 0.5, \"T\": 0.5}, {\"H\": {\"H\": 0.5, \"T\": 0.5}, \"T\": {\"H\": 0.5, \"T\": 0.5}})\n",
    "    == 1)\n",
    "assert (\n",
    "    conditional_entropy(\n",
    "        {\"H\": 0, \"T\": 1}, {\"H\": {\"H\": 0.5, \"T\": 0.5}, \"T\": {\"H\": 0.5, \"T\": 0.5}})\n",
    "    == 1)\n",
    "assert (\n",
    "    conditional_entropy(\n",
    "        {\"H\": 0.5, \"T\": 0.5}, {\"H\": {\"H\": 1, \"T\": 0}, \"T\": {\"H\": 0, \"T\": 1}})\n",
    "    == 0)\n",
    "assert (\n",
    "    conditional_entropy(\n",
    "        {\"H\": 0.5, \"T\": 0.5}, {\"H\": {\"H\": 1, \"T\": 0}, \"T\": {\"H\": 0.5, \"T\": 0.5}})\n",
    "    == 0.5)\n",
    "assert math.isclose(\n",
    "    conditional_entropy(dice_rolls_dist, cf_given_dr_dist), 0.9664712793722372)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc083682",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a7b313c25cf1c97e6cb64a071f5a4ea",
     "grade": true,
     "grade_id": "h_test-conditional_entropy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dbcfb1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The joint probability $p_{ij}$ over $i\\in \\mc{S}$ and $j\\in \\mc{T}$ can be calculated as follows\n",
    "\n",
    "$$p_{ij} = p_{i} q_{j|i}$$\n",
    "\n",
    "where, as introduced earlier, $p_i$ is the probability of $i$ and $q_{j|i}$ is the conditional probability of $j$ given $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c961cb5",
   "metadata": {},
   "source": [
    "::::{exercise}\n",
    ":label: ex:joint-distribution\n",
    "\n",
    "Define a function `joint_distribution` that\n",
    "- takes the distribution $p$ and conditional distribution $q$ as arguments, and\n",
    "- returns their joint distribution.\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5574c879",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08cf18f3d3227888c0a88db2b6d7a92a",
     "grade": false,
     "grade_id": "joint_distribution",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def joint_distribution(p, q):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05559099",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "225e7bfb79283f7a9ba139cab29d5b20",
     "grade": true,
     "grade_id": "test-joint_distribution",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-output",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "assert joint_distribution(\n",
    "    {\"H\": 0.5, \"T\": 0.5}, {\"H\": {\"H\": 0.5, \"T\": 0.5}, \"T\": {\"H\": 0.5, \"T\": 0.5}}) == {(\"H\", \"H\"): 0.25, (\"H\", \"T\"): 0.25, (\"T\", \"H\"): 0.25, (\"T\", \"T\"): 0.25}\n",
    "assert joint_distribution(\n",
    "    {\"H\": 0, \"T\": 1}, {\"H\": {\"H\": 0.5, \"T\": 0.5}, \"T\": {\"H\": 0.5, \"T\": 0.5}}) == {(\"H\", \"H\"): 0.0, (\"H\", \"T\"): 0.0, (\"T\", \"H\"): 0.5, (\"T\", \"T\"): 0.5}\n",
    "assert joint_distribution(\n",
    "    {\"H\": 0.5, \"T\": 0.5}, {\"H\": {\"H\": 1, \"T\": 0}, \"T\": {\"H\": 0, \"T\": 1}}) == {(\"H\", \"H\"): 0.5, (\"H\", \"T\"): 0.0, (\"T\", \"H\"): 0.0, (\"T\", \"T\"): 0.5}, {\n",
    "    \"H\": 0.5,\n",
    "    \"T\": 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2987b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85eabdaa66eb29dd8dc9abf4f1650bb3",
     "grade": true,
     "grade_id": "h_test-joint_distribution",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6310e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, a fundamental information identity relating the joint and conditional entropies is the [*chain rule*](https://en.wikipedia.org/wiki/Conditional_entropy#Chain_rule):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fef992",
   "metadata": {},
   "source": [
    "::::{prf:theorem}\n",
    ":label: thm:chain-rule\n",
    "\n",
    "The joint entropy is equal to\n",
    "\n",
    "$$ H(\\M{p}) + H(\\M{q}|\\M{p})$$\n",
    "\n",
    "for any distribution $\\M{p}$ over outcome $i\\in \\mc{S}$ and conditional distribution $\\M{q}$ over outcome $j\\in \\mc{T}$ given outcome $i \\in \\mc{S}$. \n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbdd3f0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you have implemented `jointly_distribute`, `conditionally_distribute`, `entropy`, and `conditional_entropy` correctly, we can verify the identity as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d248ac9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def validate_chain_rule(seq1, seq2):\n",
    "    p = distribute(seq1)\n",
    "    q = conditionally_distribute(seq1, seq2)\n",
    "    pq = jointly_distribute(seq1, seq2)\n",
    "    H_pq = entropy(pq)\n",
    "    H_p = entropy(p)\n",
    "    H_q_p = conditional_entropy(p, q)\n",
    "    print(\n",
    "        f\"\"\"Entropy of seq1: {H_p}\n",
    "Conditional entropy of seq2 given seq1: {H_q_p}\n",
    "Sum of the above entropies: {H_p + H_q_p}\n",
    "Joint entropy: {H_pq}\"\"\"\n",
    "    )\n",
    "    assert math.isclose(H_pq, H_p + H_q_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca608f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "validate_chain_rule(coin_flips, coin_flips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54392d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "validate_chain_rule(dice_rolls, coin_flips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
